{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import joblib\n",
    "\n",
    "# keras random seed https://junstar92.tistory.com/98\n",
    "\n",
    "RANDOM_SEED = 41\n",
    "np.random.seed(RANDOM_SEED)\n",
    "rn.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "from keras import optimizers, initializers, losses\n",
    "\n",
    "EPOCHS = 10000\n",
    "LEARNING_RATE = 0.0005\n",
    "OPTIMIZER = optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "INITIALIZER = initializers.HeNormal(seed=RANDOM_SEED)\n",
    "LOSS = losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data Load\n",
    "\n",
    "import joblib\n",
    "\n",
    "LINEAR = 'linear_'\n",
    "POLYNOMIAL = 'polynomial_'\n",
    "\n",
    "encoder_x = joblib.load('C:/Users/js/Desktop/AISPRAK/사회문제 해결형/'+LINEAR+'encoder_x.pkl') \n",
    "\n",
    "y = joblib.load('C:/Users/js/Desktop/AISPRAK/사회문제 해결형/'+LINEAR+'y.pkl') \n",
    "\n",
    "decoder_x = joblib.load('C:/Users/js/Desktop/AISPRAK/사회문제 해결형/'+LINEAR+'decoder_x.pkl') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_x = decoder_x.astype('float')\n",
    "decoder_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(34944,72,1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss',         \n",
    "                   min_delta=0.01,                \n",
    "                   patience=200,                 \n",
    "                   verbose=1,\n",
    "                   restore_best_weights=True)  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=chunjein&logNo=221589624838\n",
    "# https://tykimos.github.io/2018/09/14/ten-minute_introduction_to_sequence-to-sequence_learning_in_Keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(RANDOM_SEED)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, TimeDistributed\n",
    "\n",
    "BATCH_SIZE = None\n",
    "\n",
    "ENCODER_INPUT_DIM = encoder_x.shape[2]\n",
    "DECODER_INPUT_DIM = decoder_x.shape[2]\n",
    "\n",
    "ENCODER_TIMESTEP = 48\n",
    "DECODER_TIMESTEP = 72\n",
    "LATENT_DIM = 512\n",
    "\n",
    "# Encoder\n",
    "\n",
    "encoder_inputs = Input(shape=(ENCODER_TIMESTEP, ENCODER_INPUT_DIM))\n",
    "\n",
    "lstm_enc = LSTM(LATENT_DIM, activation='relu', return_sequences=True)(encoder_inputs)\n",
    "\n",
    "_, latent_c, latent_h = LSTM(LATENT_DIM, activation='relu', return_sequences=False, return_state=True)(lstm_enc) # return_sequences = True는 timestep별 출력 , return_state = True, last_hidden_state 출력\n",
    "\n",
    "encoder_output = [latent_c, latent_h]\n",
    "\n",
    "# Decoder\n",
    "\n",
    "decoder_inputs = Input(shape=(DECODER_TIMESTEP, DECODER_INPUT_DIM))\n",
    "\n",
    "lstm_dec = LSTM(LATENT_DIM, activation='relu', return_sequences=True)(decoder_inputs)\n",
    "\n",
    "step, latent_c, latent_h = LSTM(LATENT_DIM, activation='relu', return_sequences=True, return_state=True)(lstm_dec,\n",
    "                                     initial_state=encoder_output)\n",
    "\n",
    "\n",
    "# Regressor\n",
    "\n",
    "regressor_outputs = Dense(1024, activation='relu')(step)\n",
    "\n",
    "regressor_outputs = Dense(1024, activation='relu')(regressor_outputs)\n",
    "\n",
    "\n",
    "regressor_result = TimeDistributed(layer = Dense(1, activation='linear'))(regressor_outputs)\n",
    "\n",
    "# regressor_result = TimeDistributed(layer = Dense(1, activation='linear'))(step)\n",
    "   \n",
    "model = Model([encoder_inputs, decoder_inputs], regressor_result)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=LOSS, optimizer=OPTIMIZER)\n",
    "model.fit(x = [encoder_x,decoder_x], y = y, epochs=EPOCHS, batch_size=16, callbacks=[es], validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
